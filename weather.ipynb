{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Link to predict 7 days in a week\n",
    "url=\"https://www.cwb.gov.tw/V8/C/W/County/MOD/wf7dayNC_NCSEI/ALL_Week.html?v=213930\"\n",
    "payload={}\n",
    "headers={}\n",
    "response=requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "# parse to bs4 format\n",
    "soup=BeautifulSoup(response.text, 'html.parser')\n",
    "url=\"https://www.cwb.gov.tw/V8/C/W/Town/MOD/3hr/6300200_3hr_PC.html?T=2021100700-4\"\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# dict to save all info\n",
    "weeklyPredict=dict()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get table title\n",
    "theadElement=soup.find('thead')\n",
    "headTitles=theadElement.find_all('span')\n",
    "titles=[]\n",
    "for title in headTitles:\n",
    "    titles.append(title.next_element)\n",
    "titles=titles[2:]\n",
    "weeklyPredict={\"titles\": titles}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "eachCountryBody=soup.find_all('tbody')\n",
    "for i in range (len(eachCountryBody)):\n",
    "    # Get country name, noon weather and tempture\n",
    "    countryDay=eachCountryBody[i].find('tr', class_=\"day\")\n",
    "    name_tmp=countryDay.find('span', class_=\"heading_3\")\n",
    "    time_tmp=countryDay.find('td')\n",
    "    name=name_tmp.text\n",
    "    dayTime=time_tmp.contents[1].text\n",
    "    dayWeatherIcon=countryDay.find_all('img', limit=7)\n",
    "    dayTempture=countryDay.find_all('span', class_=\"tem-C is-active\", limit=7)\n",
    "    # Get night weather and tempture\n",
    "    countryNight=eachCountryBody[i].find('tr', class_=\"night\")\n",
    "    time_tmp=countryNight.find('td')\n",
    "    nightTime=time_tmp.contents[1].text\n",
    "    nightWeatherIcon=countryNight.find_all('img', limit=7)\n",
    "    nightTempture=countryNight.find_all('span', class_=\"tem-C is-active\", limit=7)\n",
    "    # Append into array\n",
    "    weather, temp=[], []\n",
    "    for i, j, k, l in zip(dayWeatherIcon, dayTempture, nightWeatherIcon, nightTempture):\n",
    "        weather.append(i.get('title'))\n",
    "        weather.append(k.get('title'))\n",
    "        temp.append(j.text.replace(\"\\u2002-\\u2002\", \"-\"))\n",
    "        temp.append(l.text.replace(\"\\u2002-\\u2002\", \"-\"))\n",
    "    # Save each country weather and tempture information\n",
    "    weeklyPredict[name]={\"weather\": weather, \"tempture\": temp}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Link to predict per three hours\n",
    "url=\"https://www.cwb.gov.tw/V8/C/W/Town/MOD/3hr/6300200_3hr_PC.html?T=2021100700-4\"\n",
    "payload={}\n",
    "headers = {}\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "# parse to bs4 format\n",
    "soup=BeautifulSoup(response.text, 'html.parser')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "threeHrsPredict = dict()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "source": [
    "# Get predict date and each day predict times amount\n",
    "servialDay=soup.find('thead')\n",
    "allDays=servialDay.find_all('th')\n",
    "days, daySpan_num=[], []\n",
    "for date in allDays:\n",
    "    days.append(date.text)\n",
    "    daySpan_num.append(date.get('colspan'))\n",
    "days=days[1:]\n",
    "threeHrsPredict = {\"days\": days}"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[None, '7', '8', '2']"
      ]
     },
     "metadata": {},
     "execution_count": 139
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "predictInfo=soup.find('tbody')\n",
    "# time=predictInfo.find(id=\"PC3_Ti\").text\n",
    "# weather=predictInfo.find(id=\"PC3_Wx\").text\n",
    "# temp=predictInfo.find(id=\"PC3_T\").text\n",
    "# rain=predictInfo.find(id=\"PC3_Po\").text\n",
    "allTime=predictInfo.find('tr', class_=\"time\")\n",
    "allTime=allTime.find_all('span')\n",
    "allWeather=predictInfo.find_all('img')\n",
    "allTemp=predictInfo.find_all('tr')[2]\n",
    "allTemp=allTemp.find_all('span', class_=\"tem-C is-active\")\n",
    "allRain=predictInfo.find_all('tr')[4]\n",
    "allRain=allRain.find_all('td')\n",
    "\n",
    "for date in days:\n",
    "    time, weather, temp, rain=[], [], [], []\n",
    "    for t, w, tp in zip(allTime, allWeather, allTemp):\n",
    "        time.append(t.text)\n",
    "        weather.append(w.get('title'))\n",
    "        temp.append(tp.text)\n",
    "    threeHrsPredict[date]={\"time\":time, \"weather\":weather, \"temp\":temp, \"rain\":rain}\n",
    "daySpan_num, len(time), len(weather), len(temp)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([None, '7', '8', '2'], 17, 17, 17)"
      ]
     },
     "metadata": {},
     "execution_count": 148
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}